# LeadHunter Pro 深度代码分析报告

**作者**: Manus AI
**日期**: 2026年1月21日

## 摘要

本报告旨在对 LeadHunter Pro 项目进行一次全面的代码级深度分析。通过对项目的前后端代码、数据库结构、外部服务集成以及核心业务逻辑的剖析，本报告将详细阐述其搜索功能的工作流程、计费机制、缓存策略和 API 调用逻辑。分析范围涵盖了从用户界面交互到后端数据处理，再到数据库存储的全过程，旨在为项目的后续开发、维护和优化提供坚实的技术参考。

---

## 1. 项目概述

LeadHunter Pro 是一个专注于潜在客户信息挖掘的 SaaS 平台，其核心功能是根据用户设定的职位和地区等条件，从海量数据源中筛选出符合要求的潜在客户，并提供包括电话号码在内的详细联系信息。项目整体采用基于 TypeScript 的全栈开发模式，部署于 Railway 云平台，实现了高效、类型安全的前后端通信。

### 1.1 技术架构

项目采用了现代化的技术栈，确保了开发的灵活性和系统的可扩展性。前后端分离的设计思路使得各层级职责分明，便于独立开发与部署。

| 层级 | 技术栈 | 主要作用 |
| :--- | :--- | :--- |
| **前端** | React, TypeScript, Vite, TailwindCSS | 构建响应式、交互友好的用户界面 |
| **后端** | Node.js, tRPC | 提供类型安全的 API 接口，处理核心业务逻辑 |
| **数据库** | MySQL (TiDB), Drizzle ORM | 持久化存储用户信息、搜索任务、结果和缓存等数据 |
| **外部服务** | Apify, Scrape.do | 集成第三方服务进行大规模数据获取和电话号码的二次验证 |

### 1.2 核心目录结构

项目的代码结构清晰，遵循了典型的全栈项目组织方式，将前端、后端、数据库和共享代码分离到不同的目录中，便于管理和维护。

```plaintext
leadhunter-pro/
├── client/                 # 前端应用 (Vite + React)
│   └── src/
│       ├── pages/          # 核心页面组件 (搜索、进度、结果)
│       └── lib/            # 库与配置 (tRPC 客户端)
├── server/                 # 后端服务 (Node.js + tRPC)
│   ├── routers.ts          # API 路由定义
│   ├── db.ts               # 数据库操作与连接
│   └── services/           # 核心业务逻辑服务
├── drizzle/                # 数据库 ORM 相关
│   └── schema.ts           # 数据库表结构定义
└── shared/                 # 前后端共享代码 (暂未使用)
```

---

## 2. 搜索功能全景解析

搜索功能是 LeadHunter Pro 的核心。其工作流程涉及前端交互、后端处理、外部 API 调用、缓存检查、并发控制和数据验证等多个环节，构成了一个复杂而精密的系统。

### 2.1 完整工作流程

搜索任务从用户在前端界面提交搜索请求开始，到最终在结果页面展示数据结束，整个过程被划分为多个阶段，由后端的 `searchProcessorV3.ts` 文件统一调度。

1.  **前端交互与任务创建**: 用户在 `Search.tsx` 页面填写职位、地区等搜索条件，并选择搜索数量。前端会进行积分预估和检查。点击搜索后，通过 tRPC 调用后端的 `search.start` 接口。

2.  **后端任务初始化**: 后端接收到请求后，首先创建一条 `search_tasks` 记录，并扣除 **1 积分** 作为搜索基础费用。

3.  **缓存检查与数据获取**: 系统根据搜索条件（职位、地区）生成一个 MD5 哈希值作为缓存键。首先检查 `global_cache` 表中是否存在有效的缓存。如果命中，则直接使用缓存数据；如果未命中，则调用 **Apify** 的 `leads-finder` Actor 来获取原始数据，并将结果存入缓存，有效期为 **180 天**。

4.  **数据费用扣除**: 在获取到数据后，系统会根据用户请求的数量和实际返回的数据量，计算出需要处理的条目数，并一次性扣除相应的数据费用（**每条 2 积分**）。如果用户积分不足，系统会自动调整处理数量至用户可负担的最大值。

5.  **并发处理与验证**: 系统以 **15 个并发** 的规模，分批处理获取到的数据。对于包含电话号码的记录，会调用 **Scrape.do** 服务进行二次验证，以确认电话号码的有效性和机主信息。

6.  **结果存储与任务完成**: 经过处理和验证的数据被存入 `search_results` 表。所有数据处理完毕后，系统会进行最终的积分核算，如果因 API 积分耗尽等原因导致部分数据未被处理，系统会自动将未消耗的积分退还给用户。最后，更新任务状态为 `completed`。

### 2.2 数据流图

下图清晰地展示了从用户请求到数据返回的完整数据流转路径。

```mermaid
graph TD
    A[用户在前端输入搜索条件] --> B{调用 tRPC search.start};
    B --> C[后端: 创建搜索任务, 扣除1积分];
    C --> D{检查全局缓存 (apify:searchHash)};
    D -- 命中 --> E[使用缓存数据];
    D -- 未命中 --> F[调用 Apify API 获取数据];
    F --> G[缓存结果 (180天)];
    G --> E;
    E --> H[计算并一次性扣除数据费用 (数量 × 2积分)];
    H --> I{并发处理 (15条/批)};
    I -- 有电话 --> J[调用 Scrape.do 验证];
    I -- 无电话 --> K[直接处理];
    J --> L{评分算法: 姓名+年龄+地区};
    L -- 验证通过 --> M[保存验证结果];
    L -- 验证失败 --> M;
    K --> M;
    M --> N[循环处理下一批];
    N -- 全部完成 --> O[统计最终消耗, 退还多余积分];
    O --> P[更新任务状态为'completed'];
    P --> Q[前端轮询状态, 展示结果];
```

---

## 3. 积分与扣费机制

系统的计费模型基于积分系统，用户通过充值获取积分，并在使用搜索功能时消耗积分。该机制的设计兼顾了成本控制和用户体验。

### 3.1 计费标准

积分的消耗主要分为两个部分，其标准在系统配置中定义，并可在管理后台进行调整。

| 费用类型 | 消耗积分 | 扣费时机 | 说明 |
| :--- | :--- | :--- | :--- |
| **搜索基础费** | 1 积分 | 任务开始时 | 每次搜索固定收取，用于覆盖基础 API 调用成本 |
| **数据处理费** | 2 积分/条 | 获取数据后 | 按实际处理的数据条目数计算，一次性扣除 |
| **电话验证费** | 0 积分/条 | (当前免费) | 为二次验证预留的计费点，目前不收费 |

### 3.2 扣费与退款流程

系统的扣费流程是预付费模式，分两步执行，确保了平台不会超额提供服务。

1.  **第一次扣费**：在搜索任务正式开始、调用任何外部 API 之前，系统会先从用户账户扣除 **1 积分** 的基础费用。
2.  **第二次扣费**：在从 Apify 获取到数据列表后，系统会根据实际将要处理的数据量，计算出总的数据处理费用，并从用户账户中一次性扣除。这一步的设计非常关键，避免了逐条扣费带来的复杂性和性能开销。

此外，系统还设计了完善的 **积分退还机制**。如果在处理过程中因为 Scrape.do 的 API 积分耗尽、用户手动停止任务或发生其他意外错误，导致部分数据未能完成处理，系统会自动计算未处理的数据量，并将相应的积分退还到用户账户，保证了计费的公平性。

所有积分的变动，无论是扣除、充值还是退还，都会在 `credit_logs` 表中生成详细记录，便于审计和追踪。

---

## 4. 缓存系统深度剖析

为了提升性能和降低成本，LeadHunter Pro 设计了一套高效的全局缓存系统。该系统以数据库表 `global_cache` 为基础，有效地减少了对外部 API 的重复调用。

### 4.1 缓存设计与实现

缓存的核心是 **缓存键 (Cache Key)** 的生成。对于搜索功能，缓存键由固定前缀 `apify:` 和一个根据搜索条件生成的 MD5 哈希值组成。

```typescript
// server/services/searchProcessorV3.ts
function generateSearchHash(name: string, title: string, state: string): string {
  const normalized = `${name.toLowerCase().trim()}|${title.toLowerCase().trim()}|${state.toLowerCase().trim()}`;
  return crypto.createHash('md5').update(normalized).digest('hex');
}
```

当用户发起一次新的搜索时，系统会使用上述函数生成一个唯一的 `searchHash`。然后，以 `apify:{searchHash}` 作为键，在 `global_cache` 表中查找是否存在未过期的记录。

### 4.2 缓存命中逻辑

缓存的命中逻辑在 `searchProcessorV3.ts` 的阶段二中执行。

-   **缓存命中 (Cache Hit)**: 如果找到了有效的缓存记录，系统将直接从 `data` 字段（一个 JSON 对象）中读取 Apify 的搜索结果，完全跳过对 Apify API 的调用。这极大地缩短了响应时间（从几十秒缩短到一秒以内），并节省了 API 调用成本。同时，系统会自动增加该缓存记录的 `hitCount` 字段，用于统计缓存的使用频率。

-   **缓存未命中 (Cache Miss)**: 如果没有找到缓存或缓存已过期，系统将正常调用 Apify API。在获取到数据后，会将完整的结果集以相同的缓存键存入 `global_cache` 表，并设置 **180 天** 的有效期，供后续相同的搜索请求使用。

### 4.3 缓存策略评估

当前缓存策略的优势在于其 **全局共享** 的特性。不同用户发起的相同搜索请求可以共享同一份缓存，最大化了缓存的利用率。然而，也存在一个潜在的优化点：当前的 `searchHash` 生成并未包含搜索数量（`limit`）参数。这意味着，一个请求 100 条数据的搜索和一个请求 1000 条数据的搜索，如果其他条件相同，会命中同一份缓存。如果缓存中只有 100 条数据，那么请求 1000 条的用户也只能得到 100 条结果。在未来的版本中，可以考虑将 `limit` 也纳入哈希计算，以实现更精细的缓存控制。

---

## 5. 外部 API 调用与集成

外部 API 是 LeadHunter Pro 数据能力的基石。系统主要集成了 Apify 用于数据获取和 Scrape.do 用于数据验证。

### 5.1 Apify 数据获取

系统通过调用 Apify 平台上的 `code_crafter/leads-finder` Actor 来获取潜在客户的初步数据。调用时，主要传递以下参数：

-   `fetch_count`: 希望获取的数据量。
-   `contact_job_title`: 职位关键词。
-   `contact_location`: 地区关键词（例如 `california, us`）。

值得注意的是，用户在前端输入的 `name` 参数并未传递给 Apify，因为该 Actor 不支持按人名进行筛选。获取到的数据包含姓名、公司、职位、邮箱、电话和 LinkedIn 地址等基础信息。

### 5.2 Scrape.do 电话验证

为了提高电话号码的准确性，系统引入了基于 Scrape.do 的二次验证流程。这是一个网页抓取服务，系统通过它间接访问两个公开的个人信息查询网站：**TruePeopleSearch** 和 **FastPeopleSearch**。

验证流程分为两步：

1.  **第一阶段**: 首先尝试使用 **TruePeopleSearch** 进行电话号码反向查询。Scrape.do 会加载目标网页并返回其 HTML 内容。
2.  **第二阶段**: 如果第一阶段验证失败或分数不足，系统会启动备用方案，使用 **FastPeopleSearch** 进行查询。

最终，系统会选择两个来源中分数较高的一个作为验证结果。

### 5.3 验证评分算法

从 TruePeopleSearch 或 FastPeopleSearch 获取到 HTML 页面后，系统会通过解析页面内容来进行打分，以判断查找到的人是否与目标客户匹配。评分算法如下：

| 匹配项 | 分数 | 验证逻辑 |
| :--- | :--- | :--- |
| **姓名匹配** | +40 | 页面中找到的人名同时包含目标的姓和名 |
| **年龄在范围内** | +30 | 找到的年龄在用户设定的范围内（默认为 50-79 岁） |
| **州匹配** | +20 | 页面中包含目标所在的州名 |
| **城市匹配** | +10 | 页面中包含目标所在的城市名 |

**验证通过条件**：必须 **姓名匹配** 且 **总分达到 70 分**。这一严格的评分机制确保了电话号码和机主身份的高度匹配，是提升数据质量的关键环节。

### 5.4 并发与错误处理

为了在处理速度和 API 稳定性之间取得平衡，系统在进行电话验证时采用了 **15 个并发** 的限制。数据被分成小批量，通过 `Promise.all` 进行并发处理。

同时，API 调用逻辑中包含了完善的错误处理和重试机制。对于网络超时、服务器错误（5xx）或请求频率限制（429）等 **可重试错误**，系统会自动重试 **1 次**。对于 Scrape.do 的 API 积分耗尽（返回 401 错误），系统会立即停止验证流程，并将未消耗的积分退还给用户。

---

## 6. 数据库设计

项目的数据库使用 Drizzle ORM 进行管理，表结构定义在 `drizzle/schema.ts` 文件中，设计合理，满足了业务需求。

### 6.1 核心数据表

| 表名 | 主要功能 |
| :--- | :--- |
| `users` | 存储用户信息、积分余额和角色权限 |
| `search_tasks` | 记录每一次搜索任务的状态、参数、进度和日志 |
| `search_results` | 存储最终处理完成的潜在客户数据及验证信息 |
| `global_cache` | 全局缓存表，用于存储 Apify 搜索结果 |
| `credit_logs` | 记录所有积分变动，用于审计和对账 |
| `api_logs` | 记录每一次对外部 API 的调用详情，便于调试和分析 |
| `system_configs` | 存储系统级的配置参数，如计费标准、API 密钥等 |

### 6.2 关键表结构分析

-   **search_tasks**: 该表是追踪搜索进度的核心。其 `logs` 字段（JSON 类型）非常关键，它以数组形式实时记录了后端处理过程中的详细日志，前端通过轮询该字段来向用户展示生动的执行过程。

-   **global_cache**: `cacheKey` 字段被设置为唯一索引，确保了缓存的快速查找。`expiresAt` 字段使得过期缓存的判断和清理变得简单高效。

-   **credit_logs**: `amount` 字段使用负数表示扣除，正数表示增加，设计直观。`relatedTaskId` 和 `relatedOrderId` 字段将积分变动与具体的业务操作关联起来，提供了完整的可追溯性。

---

## 7. 总结与建议

LeadHunter Pro 在架构设计、业务逻辑实现和技术选型上都表现出了较高的水准。整个系统逻辑严谨，流程闭环，特别是在计费、缓存和数据验证等关键环节上考虑周全。

### 7.1 系统优势

-   **类型安全**: 全栈 tRPC 的应用保证了前后端数据交互的类型安全，减少了运行时错误。
-   **高效缓存**: 全局共享的缓存机制极大地提升了重复搜索的性能，并有效降低了 API 成本。
-   **精确计费**: 分步、预付费的扣费模型结合自动退款机制，实现了公平、精确的计费。
-   **高质量验证**: 通过多源交叉验证和严格的评分算法，保证了电话号码等核心数据的准确性。
-   **良好体验**: 前端通过实时日志和进度展示，为用户提供了透明、安心的等待体验。

### 7.2 潜在优化点

-   **缓存键优化**: 如前文所述，可以考虑将搜索数量 `limit` 纳入缓存键的生成，以支持对不同规模搜索的精细化缓存。
-   **API 密钥管理**: 目前 API 密钥通过数据库配置，虽然灵活，但从安全性角度考虑，更推荐完全使用环境变量或专门的密钥管理服务（如 Vault）来存储敏感凭证。
-   **定时清理任务**: 建议为系统增加一个定时的 cron job，每日自动调用 `cleanExpiredCache()` 函数，清理数据库中的过期缓存记录，保持数据库的健康。
-   **数据处理监控**: 可以引入更详细的监控和告警机制，例如当 Scrape.do 的 API 积分即将耗尽时，或当 API 错误率在短时间内飙升时，能及时通知管理员。

总而言之，LeadHunter Pro 是一个设计精良、功能强大的潜在客户数据平台。本报告所提供的分析和建议，希望能为项目未来的迭代和发展提供有价值的参考。
